{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import better_pipeline as bp\n",
    "import pipeline as pl\n",
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_data('/home/student/Downloads/projects_2012_2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124976 entries, 0 to 124975\n",
      "Data columns (total 26 columns):\n",
      "projectid                                 124976 non-null object\n",
      "teacher_acctid                            124976 non-null object\n",
      "schoolid                                  124976 non-null object\n",
      "school_ncesid                             115743 non-null float64\n",
      "school_latitude                           124976 non-null float64\n",
      "school_longitude                          124976 non-null float64\n",
      "school_city                               124976 non-null object\n",
      "school_state                              124976 non-null object\n",
      "school_metro                              109752 non-null object\n",
      "school_district                           124804 non-null object\n",
      "school_county                             124976 non-null object\n",
      "school_charter                            124976 non-null object\n",
      "school_magnet                             124976 non-null object\n",
      "teacher_prefix                            124976 non-null object\n",
      "primary_focus_subject                     124961 non-null object\n",
      "primary_focus_area                        124961 non-null object\n",
      "secondary_focus_subject                   84420 non-null object\n",
      "secondary_focus_area                      84420 non-null object\n",
      "resource_type                             124959 non-null object\n",
      "poverty_level                             124976 non-null object\n",
      "grade_level                               124973 non-null object\n",
      "total_price_including_optional_support    124976 non-null float64\n",
      "students_reached                          124917 non-null float64\n",
      "eligible_double_your_impact_match         124976 non-null object\n",
      "date_posted                               124976 non-null object\n",
      "datefullyfunded                           124976 non-null object\n",
      "dtypes: float64(5), object(21)\n",
      "memory usage: 24.8+ MB\n"
     ]
    }
   ],
   "source": [
    "pl.df_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projectid</th>\n",
       "      <th>teacher_acctid</th>\n",
       "      <th>schoolid</th>\n",
       "      <th>school_ncesid</th>\n",
       "      <th>school_latitude</th>\n",
       "      <th>school_longitude</th>\n",
       "      <th>school_city</th>\n",
       "      <th>school_state</th>\n",
       "      <th>school_metro</th>\n",
       "      <th>school_district</th>\n",
       "      <th>...</th>\n",
       "      <th>secondary_focus_subject</th>\n",
       "      <th>secondary_focus_area</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>datefullyfunded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001ccc0e81598c4bd86bacb94d7acb</td>\n",
       "      <td>96963218e74e10c3764a5cfb153e6fea</td>\n",
       "      <td>9f3f9f2c2da7edda5648ccd10554ed8c</td>\n",
       "      <td>1.709930e+11</td>\n",
       "      <td>41.807654</td>\n",
       "      <td>-87.673257</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>urban</td>\n",
       "      <td>Pershing Elem Network</td>\n",
       "      <td>...</td>\n",
       "      <td>Visual Arts</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1498.61</td>\n",
       "      <td>31.0</td>\n",
       "      <td>f</td>\n",
       "      <td>4/14/13</td>\n",
       "      <td>5/2/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000fa3aa8f6649abab23615b546016d</td>\n",
       "      <td>2a578595fe351e7fce057e048c409b18</td>\n",
       "      <td>3432ed3d4466fac2f2ead83ab354e333</td>\n",
       "      <td>6.409801e+10</td>\n",
       "      <td>34.296596</td>\n",
       "      <td>-119.296596</td>\n",
       "      <td>Ventura</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Ventura Unif School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>282.47</td>\n",
       "      <td>28.0</td>\n",
       "      <td>t</td>\n",
       "      <td>4/7/12</td>\n",
       "      <td>4/18/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000134f07d4b30140d63262c871748ff</td>\n",
       "      <td>26bd60377bdbffb53a644a16c5308e82</td>\n",
       "      <td>dc8dcb501c3b2bb0b10e9c6ee2cd8afd</td>\n",
       "      <td>6.227100e+10</td>\n",
       "      <td>34.078625</td>\n",
       "      <td>-118.257834</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Los Angeles Unif Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1012.38</td>\n",
       "      <td>56.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/30/12</td>\n",
       "      <td>4/15/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001f2d0b3827bba67cdbeaa248b832d</td>\n",
       "      <td>15d900805d9d716c051c671827109f45</td>\n",
       "      <td>8bea7e8c6e4279fca6276128db89292e</td>\n",
       "      <td>3.600090e+11</td>\n",
       "      <td>40.687286</td>\n",
       "      <td>-73.988217</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>New York City Dept Of Ed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>175.33</td>\n",
       "      <td>23.0</td>\n",
       "      <td>f</td>\n",
       "      <td>10/11/12</td>\n",
       "      <td>12/5/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004536db996ba697ca72c9e058bfe69</td>\n",
       "      <td>400f8b82bb0143f6a40b217a517fe311</td>\n",
       "      <td>fbdefab6fe41e12c55886c610c110753</td>\n",
       "      <td>3.606870e+11</td>\n",
       "      <td>40.793018</td>\n",
       "      <td>-73.205635</td>\n",
       "      <td>Central Islip</td>\n",
       "      <td>NY</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Central Islip Union Free SD</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>3591.11</td>\n",
       "      <td>150.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/8/13</td>\n",
       "      <td>3/25/13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          projectid                    teacher_acctid  \\\n",
       "0  00001ccc0e81598c4bd86bacb94d7acb  96963218e74e10c3764a5cfb153e6fea   \n",
       "1  0000fa3aa8f6649abab23615b546016d  2a578595fe351e7fce057e048c409b18   \n",
       "2  000134f07d4b30140d63262c871748ff  26bd60377bdbffb53a644a16c5308e82   \n",
       "3  0001f2d0b3827bba67cdbeaa248b832d  15d900805d9d716c051c671827109f45   \n",
       "4  0004536db996ba697ca72c9e058bfe69  400f8b82bb0143f6a40b217a517fe311   \n",
       "\n",
       "                           schoolid  school_ncesid  school_latitude  \\\n",
       "0  9f3f9f2c2da7edda5648ccd10554ed8c   1.709930e+11        41.807654   \n",
       "1  3432ed3d4466fac2f2ead83ab354e333   6.409801e+10        34.296596   \n",
       "2  dc8dcb501c3b2bb0b10e9c6ee2cd8afd   6.227100e+10        34.078625   \n",
       "3  8bea7e8c6e4279fca6276128db89292e   3.600090e+11        40.687286   \n",
       "4  fbdefab6fe41e12c55886c610c110753   3.606870e+11        40.793018   \n",
       "\n",
       "   school_longitude    school_city school_state school_metro  \\\n",
       "0        -87.673257        Chicago           IL        urban   \n",
       "1       -119.296596        Ventura           CA        urban   \n",
       "2       -118.257834    Los Angeles           CA        urban   \n",
       "3        -73.988217       Brooklyn           NY        urban   \n",
       "4        -73.205635  Central Islip           NY     suburban   \n",
       "\n",
       "                school_district       ...       secondary_focus_subject  \\\n",
       "0         Pershing Elem Network       ...                   Visual Arts   \n",
       "1  Ventura Unif School District       ...          Literature & Writing   \n",
       "2     Los Angeles Unif Sch Dist       ...               Social Sciences   \n",
       "3      New York City Dept Of Ed       ...                           NaN   \n",
       "4   Central Islip Union Free SD       ...          Literature & Writing   \n",
       "\n",
       "  secondary_focus_area resource_type    poverty_level    grade_level  \\\n",
       "0     Music & The Arts      Supplies  highest poverty  Grades PreK-2   \n",
       "1  Literacy & Language         Books  highest poverty     Grades 3-5   \n",
       "2     History & Civics    Technology     high poverty     Grades 3-5   \n",
       "3                  NaN         Books     high poverty  Grades PreK-2   \n",
       "4  Literacy & Language    Technology     high poverty  Grades PreK-2   \n",
       "\n",
       "  total_price_including_optional_support students_reached  \\\n",
       "0                                1498.61             31.0   \n",
       "1                                 282.47             28.0   \n",
       "2                                1012.38             56.0   \n",
       "3                                 175.33             23.0   \n",
       "4                                3591.11            150.0   \n",
       "\n",
       "  eligible_double_your_impact_match date_posted datefullyfunded  \n",
       "0                                 f     4/14/13          5/2/13  \n",
       "1                                 t      4/7/12         4/18/12  \n",
       "2                                 f     1/30/12         4/15/12  \n",
       "3                                 f    10/11/12         12/5/12  \n",
       "4                                 f      1/8/13         3/25/13  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.df_head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_ncesid</th>\n",
       "      <th>school_latitude</th>\n",
       "      <th>school_longitude</th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.157430e+05</td>\n",
       "      <td>124976.000000</td>\n",
       "      <td>124976.000000</td>\n",
       "      <td>124976.000000</td>\n",
       "      <td>124917.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.448448e+11</td>\n",
       "      <td>36.827284</td>\n",
       "      <td>-95.859299</td>\n",
       "      <td>654.011811</td>\n",
       "      <td>95.445760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.644728e+11</td>\n",
       "      <td>4.963669</td>\n",
       "      <td>18.392876</td>\n",
       "      <td>1098.015854</td>\n",
       "      <td>163.481912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000050e+10</td>\n",
       "      <td>18.249140</td>\n",
       "      <td>-171.690554</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.344101e+10</td>\n",
       "      <td>33.872504</td>\n",
       "      <td>-117.806418</td>\n",
       "      <td>345.810000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.200870e+11</td>\n",
       "      <td>36.617410</td>\n",
       "      <td>-90.101563</td>\n",
       "      <td>510.500000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.704880e+11</td>\n",
       "      <td>40.676156</td>\n",
       "      <td>-80.713740</td>\n",
       "      <td>752.960000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.100010e+11</td>\n",
       "      <td>65.672562</td>\n",
       "      <td>-66.628036</td>\n",
       "      <td>164382.840000</td>\n",
       "      <td>12143.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       school_ncesid  school_latitude  school_longitude  \\\n",
       "count   1.157430e+05    124976.000000     124976.000000   \n",
       "mean    2.448448e+11        36.827284        -95.859299   \n",
       "std     1.644728e+11         4.963669         18.392876   \n",
       "min     1.000050e+10        18.249140       -171.690554   \n",
       "25%     6.344101e+10        33.872504       -117.806418   \n",
       "50%     2.200870e+11        36.617410        -90.101563   \n",
       "75%     3.704880e+11        40.676156        -80.713740   \n",
       "max     6.100010e+11        65.672562        -66.628036   \n",
       "\n",
       "       total_price_including_optional_support  students_reached  \n",
       "count                           124976.000000     124917.000000  \n",
       "mean                               654.011811         95.445760  \n",
       "std                               1098.015854        163.481912  \n",
       "min                                 92.000000          1.000000  \n",
       "25%                                345.810000         23.000000  \n",
       "50%                                510.500000         30.000000  \n",
       "75%                                752.960000        100.000000  \n",
       "max                             164382.840000      12143.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.df_description(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "projectid                                     0\n",
       "teacher_acctid                                0\n",
       "schoolid                                      0\n",
       "school_ncesid                              9233\n",
       "school_latitude                               0\n",
       "school_longitude                              0\n",
       "school_city                                   0\n",
       "school_state                                  0\n",
       "school_metro                              15224\n",
       "school_district                             172\n",
       "school_county                                 0\n",
       "school_charter                                0\n",
       "school_magnet                                 0\n",
       "teacher_prefix                                0\n",
       "primary_focus_subject                        15\n",
       "primary_focus_area                           15\n",
       "secondary_focus_subject                   40556\n",
       "secondary_focus_area                      40556\n",
       "resource_type                                17\n",
       "poverty_level                                 0\n",
       "grade_level                                   3\n",
       "total_price_including_optional_support        0\n",
       "students_reached                             59\n",
       "eligible_double_your_impact_match             0\n",
       "date_posted                                   0\n",
       "datefullyfunded                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.df_missing_values(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the label variable: Label variable is 1 if project doesn't get fully funded within the 60 days from date posted, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['days_financed'] = pd.to_datetime(data['datefullyfunded']) - pd.to_datetime(data['date_posted'])\n",
    "data['label'] = data['days_financed'].dt.days.apply(lambda x: 0 if x <= 60 else 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the attributes that are not necessary for prediction. These are 'projectid', 'teacher_acctid', 'schoolid','school_ncesid', which are identifiers. \n",
    "Also, although very important, we will leave behind geographic location attributes:          'school_longitude', 'school_district', 'school_county', 'school_city' and 'school_state', as well as the  attributes used to construct the label:  'datefullyfunded', 'days_financed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lst = ['projectid', 'teacher_acctid', 'schoolid',\n",
    "            'school_ncesid', 'school_latitude', \n",
    "            'school_longitude', 'school_district', \n",
    "            'school_county', 'secondary_focus_subject',\n",
    "            'secondary_focus_area','primary_focus_subject']\n",
    "unnecesary_lst = ['datefullyfunded', 'days_financed', 'school_city', 'school_state']\n",
    "pl.drop_features(data, drop_lst)\n",
    "pl.drop_features(data, unnecesary_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An additional function that is also necesary is the boolean conversor from string to 1/0. Some of the variables are in \"t\", \"f\" and we want them to be integers 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(data,var,dic):\n",
    "    data = data.replace({var:dic})\n",
    "\n",
    "\n",
    "tf_dic = {'t': 1, 'f':0}\n",
    "lst_to_convert = ['school_charter', 'school_magnet', 'eligible_double_your_impact_match' ]\n",
    "for var in  lst_to_convert:\n",
    "    convert_to_int(data,var,tf_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_to_fill = ['primary_focus_area',\n",
    "               'resource_type', 'grade_level', 'students_reached']\n",
    "pl.fill_missing(data,lst_to_fill,form = False)\n",
    "lst_dummies = ['school_metro', \n",
    "               'primary_focus_area', 'resource_type', 'poverty_level',\n",
    "              'grade_level']\n",
    "data = pl.to_dummies(data,lst_dummies)\n",
    "\n",
    "pl.drop_features(data, lst_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_t = pd.get_dummies(data['teacher_prefix'])\n",
    "d_t_lst = list(d_t.columns)\n",
    "d_t['female_teacher'] = d_t['Dr.'] + d_t['Ms.'] + d_t['Mrs.'] \n",
    "d_t['male_teacher'] = d_t['Mr.']\n",
    "pl.drop_features(d_t, d_t_lst)\n",
    "data.join(d_t)\n",
    "\n",
    "final_drop = ['teacher_prefix']\n",
    "pl.drop_features(data, final_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school_charter', 'school_magnet',\n",
       "       'total_price_including_optional_support', 'students_reached',\n",
       "       'eligible_double_your_impact_match', 'date_posted', 'label',\n",
       "       'school_metro_rural', 'school_metro_suburban', 'school_metro_urban',\n",
       "       'primary_focus_area_Applied Learning',\n",
       "       'primary_focus_area_Health & Sports',\n",
       "       'primary_focus_area_History & Civics',\n",
       "       'primary_focus_area_Literacy & Language',\n",
       "       'primary_focus_area_Math & Science',\n",
       "       'primary_focus_area_Music & The Arts',\n",
       "       'primary_focus_area_Special Needs', 'resource_type_Books',\n",
       "       'resource_type_Other', 'resource_type_Supplies',\n",
       "       'resource_type_Technology', 'resource_type_Trips',\n",
       "       'resource_type_Visitors', 'poverty_level_high poverty',\n",
       "       'poverty_level_highest poverty', 'poverty_level_low poverty',\n",
       "       'poverty_level_moderate poverty', 'grade_level_Grades 3-5',\n",
       "       'grade_level_Grades 6-8', 'grade_level_Grades 9-12',\n",
       "       'grade_level_Grades PreK-2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_val(start_time, end_time, window_train, window_test):\n",
    "    validation_lst = []\n",
    "    start_time_date = datetime.strptime(start_time, '%Y-%m-%d')\n",
    "    end_time_date = datetime.strptime(end_time, '%Y-%m-%d')\n",
    "    test_end_time = end_time_date - relativedelta(days=+1)\n",
    "    train_start_time = start_time_date\n",
    "    while test_end_time <= end_time_date:\n",
    "        train_end_time = train_start_time + relativedelta(months=+window_train)\n",
    "        test_start_time = train_end_time + relativedelta(days=+1)\n",
    "        test_end_time = test_start_time + relativedelta(months=+window_test)\n",
    "        validation_lst.append([train_start_time,train_end_time,test_start_time,test_end_time])\n",
    "        window_train +=6\n",
    "    return validation_lst\n",
    "    \n",
    "def temp_spl(data,temp_var,validation_elem, label):\n",
    "    train_start,train_end,test_start,test_end = validation_elem\n",
    "    data[temp_var] = pd.to_datetime(data[temp_var])\n",
    "    train_data = data[(train_start <= data[temp_var]) & ( data[temp_var] <= train_end)]\n",
    "    X_train = np.array(train_data.drop([label,temp_var],1))\n",
    "    y_train = np.array(train_data[label])\n",
    "    test_data = data[(test_start <= data[temp_var] ) & (data[temp_var]<= test_end)]\n",
    "    X_test = np.array(test_data.drop([label,temp_var],1))\n",
    "    y_test = np.array(test_data[label])\n",
    "    return X_train, X_test, y_train, y_test        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[datetime.datetime(2012, 1, 1, 0, 0), datetime.datetime(2012, 7, 1, 0, 0), datetime.datetime(2012, 7, 2, 0, 0), datetime.datetime(2013, 1, 2, 0, 0)], [datetime.datetime(2012, 1, 1, 0, 0), datetime.datetime(2013, 1, 1, 0, 0), datetime.datetime(2013, 1, 2, 0, 0), datetime.datetime(2013, 7, 2, 0, 0)], [datetime.datetime(2012, 1, 1, 0, 0), datetime.datetime(2013, 7, 1, 0, 0), datetime.datetime(2013, 7, 2, 0, 0), datetime.datetime(2014, 1, 2, 0, 0)]]\n"
     ]
    }
   ],
   "source": [
    "lst = temp_val('2012-01-01','2013-12-31',6,6)\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[datetime.datetime(2012, 1, 1, 0, 0), datetime.datetime(2012, 7, 1, 0, 0), datetime.datetime(2012, 7, 2, 0, 0), datetime.datetime(2013, 1, 2, 0, 0)], [datetime.datetime(2012, 1, 1, 0, 0), datetime.datetime(2013, 1, 1, 0, 0), datetime.datetime(2013, 1, 2, 0, 0), datetime.datetime(2013, 7, 2, 0, 0)], [datetime.datetime(2012, 1, 1, 0, 0), datetime.datetime(2013, 7, 1, 0, 0), datetime.datetime(2013, 7, 2, 0, 0), datetime.datetime(2014, 1, 2, 0, 0)]]\n",
      "(26617, 30) (32822, 30) (26617,) (32822,)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(59346, 30) (21613, 30) (59346,) (21613,)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(80931, 30) (44045, 30) (80931,) (44045,)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "lst = temp_val('2012-01-01','2013-12-31',6,6)\n",
    "print(lst)\n",
    "for elem in lst:\n",
    "    X_train, X_test, y_train, y_test = temp_spl(data,'date_posted',elem,'label')\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013-01-01 00:00:00'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(lst[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "projectid                                         object\n",
       "teacher_acctid                                    object\n",
       "schoolid                                          object\n",
       "school_ncesid                                    float64\n",
       "school_latitude                                  float64\n",
       "school_longitude                                 float64\n",
       "school_city                                       object\n",
       "school_state                                      object\n",
       "school_metro                                      object\n",
       "school_district                                   object\n",
       "school_county                                     object\n",
       "school_charter                                    object\n",
       "school_magnet                                     object\n",
       "teacher_prefix                                    object\n",
       "primary_focus_subject                             object\n",
       "primary_focus_area                                object\n",
       "secondary_focus_subject                           object\n",
       "secondary_focus_area                              object\n",
       "resource_type                                     object\n",
       "poverty_level                                     object\n",
       "grade_level                                       object\n",
       "total_price_including_optional_support           float64\n",
       "students_reached                                 float64\n",
       "eligible_double_your_impact_match                 object\n",
       "date_posted                               datetime64[ns]\n",
       "datefullyfunded                                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, svm, metrics, tree, decomposition, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier, OrthogonalMatchingPursuit, RandomizedLogisticRegression\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "# for jupyter notebooks\n",
    "#%matplotlib inline\n",
    "\n",
    "# if you're running this in a jupyter notebook, print out the graphs\n",
    "NOTEBOOK = 0\n",
    "\n",
    "def define_clfs_params(grid_size):\n",
    "    \"\"\"Define defaults for different classifiers.\n",
    "    Define three types of grids:\n",
    "    Test: for testing your code\n",
    "    Small: small grid\n",
    "    Large: Larger grid that has a lot more parameter sweeps\n",
    "    \"\"\"\n",
    "\n",
    "    clfs = {'RF': RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "        'ET': ExtraTreesClassifier(n_estimators=10, n_jobs=-1, criterion='entropy'),\n",
    "        'AB': AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=200),\n",
    "        'LR': LogisticRegression(penalty='l1', C=1e5),\n",
    "        'SVM': svm.SVC(kernel='linear', probability=True, random_state=0),\n",
    "        'GB': GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10),\n",
    "        'NB': GaussianNB(),\n",
    "        'DT': DecisionTreeClassifier(),\n",
    "        'SGD': SGDClassifier(loss=\"hinge\", penalty=\"l2\"),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=3) \n",
    "            }\n",
    "\n",
    "    large_grid = { \n",
    "    'RF':{'n_estimators': [1,10,100,1000,10000], 'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10], 'n_jobs': [-1]},\n",
    "    'LR': { 'penalty': ['l1','l2'], 'C': [0.00001,0.0001,0.001,0.01,0.1,1,10]},\n",
    "    'SGD': { 'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "    'ET': { 'n_estimators': [1,10,100,1000,10000], 'criterion' : ['gini', 'entropy'] ,'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10], 'n_jobs': [-1]},\n",
    "    'AB': { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "    'GB': {'n_estimators': [1,10,100,1000,10000], 'learning_rate' : [0.001,0.01,0.05,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [1,3,5,10,20,50,100]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "    'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "           }\n",
    "    \n",
    "    small_grid = { \n",
    "    'RF':{'n_estimators': [10,100], 'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]},\n",
    "    'LR': { 'penalty': ['l1','l2'], 'C': [0.00001,0.001,0.1,1,10]},\n",
    "    'SGD': { 'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "    'ET': { 'n_estimators': [10,100], 'criterion' : ['gini', 'entropy'] ,'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]},\n",
    "    'AB': { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "    'GB': {'n_estimators': [10,100], 'learning_rate' : [0.001,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [5,50]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "    'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "           }\n",
    "    \n",
    "    test_grid = { \n",
    "    'RF':{'n_estimators': [1], 'max_depth': [1], 'max_features': ['sqrt'],'min_samples_split': [10]},\n",
    "    'LR': { 'penalty': ['l1'], 'C': [0.01]},\n",
    "    'SGD': { 'loss': ['perceptron'], 'penalty': ['l2']},\n",
    "    'ET': { 'n_estimators': [1], 'criterion' : ['gini'] ,'max_depth': [1], 'max_features': ['sqrt'],'min_samples_split': [10]},\n",
    "    'AB': { 'algorithm': ['SAMME'], 'n_estimators': [1]},\n",
    "    'GB': {'n_estimators': [1], 'learning_rate' : [0.1],'subsample' : [0.5], 'max_depth': [1]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini'], 'max_depth': [1],'min_samples_split': [10]},\n",
    "    'SVM' :{'C' :[0.01],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [5],'weights': ['uniform'],'algorithm': ['auto']}\n",
    "           }\n",
    "    \n",
    "    if (grid_size == 'large'):\n",
    "        return clfs, large_grid\n",
    "    elif (grid_size == 'small'):\n",
    "        return clfs, small_grid\n",
    "    elif (grid_size == 'test'):\n",
    "        return clfs, test_grid\n",
    "    else:\n",
    "        return 0, 0\n",
    "\n",
    "\n",
    "    \n",
    "models_to_run=['RF','DT','KNN','LR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a set of helper function to do machine learning evalaution\n",
    "\n",
    "def joint_sort_descending(l1, l2):\n",
    "    # l1 and l2 have to be numpy arrays\n",
    "    idx = np.argsort(l1)[::-1]\n",
    "    return l1[idx], l2[idx]\n",
    "\n",
    "def generate_binary_at_k(y_scores, k):\n",
    "    cutoff_index = int(len(y_scores) * (k / 100.0))\n",
    "    test_predictions_binary = [1 if x < cutoff_index else 0 for x in range(len(y_scores))]\n",
    "    return test_predictions_binary\n",
    "\n",
    "def precision_at_k(y_true, y_scores, k):\n",
    "    y_scores, y_true = joint_sort_descending(np.array(y_scores), np.array(y_true))\n",
    "    preds_at_k = generate_binary_at_k(y_scores, k)\n",
    "    #precision, _, _, _ = metrics.precision_recall_fscore_support(y_true, preds_at_k)\n",
    "    #precision = precision[1]  # only interested in precision for label 1\n",
    "    precision = precision_score(y_true, preds_at_k)\n",
    "    return precision\n",
    "\n",
    "def recall_at_k(y_true, y_scores, k):\n",
    "    #y_scores_sorted, y_true_sorted = zip(*sorted(zip(y_scores, y_true), reverse=True))\n",
    "    y_scores_sorted, y_true_sorted = joint_sort_descending(np.array(y_scores), np.array(y_true))\n",
    "    preds_at_k = generate_binary_at_k(y_scores_sorted, k)\n",
    "    #precision, _, _, _ = metrics.precision_recall_fscore_support(y_true, preds_at_k)\n",
    "    #precision = precision[1]  # only interested in precision for label 1\n",
    "    recall = recall_score(y_true_sorted, preds_at_k)\n",
    "    return recall\n",
    "\n",
    "def f1_at_k(y_true, y_scores, k):\n",
    "    y_scores_sorted, y_true_sorted = joint_sort_descending(np.array(y_scores), np.array(y_true))\n",
    "    preds_at_k = generate_binary_at_k(y_scores_sorted, k)\n",
    "    recall = recall_score(y_true_sorted, preds_at_k)\n",
    "    precision = precision_score(y_true_sorted, preds_at_k)\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return F1\n",
    "\n",
    "def accurate(y_test_sorted_,y_pred_sorted):\n",
    "    accure = metrics.accuracy_score(y_test_sorted_,y_pred_sorted)\n",
    "    return accure\n",
    "\n",
    "def plot_precision_recall_n(y_true, y_prob, model_name):\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    y_score = y_prob\n",
    "    precision_curve, recall_curve, pr_thresholds = precision_recall_curve(y_true, y_score)\n",
    "    precision_curve = precision_curve[:-1]\n",
    "    recall_curve = recall_curve[:-1]\n",
    "    pct_above_per_thresh = []\n",
    "    number_scored = len(y_score)\n",
    "    for value in pr_thresholds:\n",
    "        num_above_thresh = len(y_score[y_score>=value])\n",
    "        pct_above_thresh = num_above_thresh / float(number_scored)\n",
    "        pct_above_per_thresh.append(pct_above_thresh)\n",
    "    pct_above_per_thresh = np.array(pct_above_per_thresh)\n",
    "    \n",
    "    plt.clf()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(pct_above_per_thresh, precision_curve, 'b')\n",
    "    ax1.set_xlabel('percent of population')\n",
    "    ax1.set_ylabel('precision', color='b')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(pct_above_per_thresh, recall_curve, 'r')\n",
    "    ax2.set_ylabel('recall', color='r')\n",
    "    ax1.set_ylim([0,1])\n",
    "    ax1.set_ylim([0,1])\n",
    "    ax2.set_xlim([0,1])\n",
    "    \n",
    "    name = model_name\n",
    "    plt.title(name)\n",
    "    #plt.savefig(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "clfs, grid = define_clfs_params('small')\n",
    "models_to_run=['RF','DT','LR']\n",
    "X = np.array(data.drop(['label'],1))\n",
    "y = np.array(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_loop(models_to_run, clfs, grid, X, y):\n",
    "    \"\"\"Runs the loop using models_to_run, clfs, gridm and the data\n",
    "    \"\"\"\n",
    "    results_df =  pd.DataFrame(columns=('model_type','clf', 'parameters', 'auc-roc','p_at_5', \n",
    "                                        'p_at_10', 'p_at_20','p_at_30', 'p_at_40','p_at_50',\n",
    "                                        'r_at_5','r_at_10','r_at_20','r_at_30','r_at_40','r_at_50',\n",
    "                                        'f1_at_5','f1_at_10','f1_at_20','f1_at_30','f1_at_40','f1_at_50'))\n",
    "    \n",
    "\n",
    "    for n in range(1, 2):\n",
    "        # create training and valdation sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "        print(type(X_train))\n",
    "        print(type(y_train))\n",
    "        for index,clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "            print(models_to_run[index])\n",
    "            parameter_values = grid[models_to_run[index]]\n",
    "            for p in ParameterGrid(parameter_values):\n",
    "                try:\n",
    "                    clf.set_params(**p)\n",
    "                    y_pred_probs = clf.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "                    #y_pred = clf.fit(X_train, y_train).predict(X_test)[:,1]\n",
    "                    # you can also store the model, feature importances, and prediction scores\n",
    "                    # we're only storing the metrics for now\n",
    "                    #y_pred_probs_sorted, y_pred_sorted, y_test_sorted = zip(*sorted(zip(y_pred_probs, y_pred, y_test), reverse=True))\n",
    "                    y_pred_probs_sorted, y_test_sorted = zip(*sorted(zip(y_pred_probs,y_test), reverse=True))\n",
    "                    #y_pred_sorted, y_test_sorted_ = zip(*sorted(zip(y_pred,y_test), reverse=True))\n",
    "                    results_df.loc[len(results_df)] = [models_to_run[index],clf, p,\n",
    "                                                       roc_auc_score(y_test, y_pred_probs),\n",
    "                                                       precision_at_k(y_test_sorted, y_pred_probs_sorted, 5.0),\n",
    "                                                       precision_at_k(y_test_sorted, y_pred_probs_sorted, 10.0),\n",
    "                                                       precision_at_k(y_test_sorted, y_pred_probs_sorted, 20.0),\n",
    "                                                       precision_at_k(y_test_sorted, y_pred_probs_sorted, 30.0),\n",
    "                                                       precision_at_k(y_test_sorted, y_pred_probs_sorted, 40.0),\n",
    "                                                       precision_at_k(y_test_sorted, y_pred_probs_sorted, 50.0),\n",
    "                                                       recall_at_k(y_test_sorted, y_pred_probs_sorted, 5.0),\n",
    "                                                       recall_at_k(y_test_sorted, y_pred_probs_sorted,10.0),\n",
    "                                                       recall_at_k(y_test_sorted, y_pred_probs_sorted, 20.0),\n",
    "                                                       recall_at_k(y_test_sorted, y_pred_probs_sorted, 30.0),\n",
    "                                                       recall_at_k(y_test_sorted, y_pred_probs_sorted, 40.0),\n",
    "                                                       recall_at_k(y_test_sorted, y_pred_probs_sorted, 50.0),\n",
    "                                                       f1_at_k(y_test_sorted, y_pred_probs_sorted, 5.0),\n",
    "                                                       f1_at_k(y_test_sorted, y_pred_probs_sorted,10.0),\n",
    "                                                       f1_at_k(y_test_sorted, y_pred_probs_sorted, 20.0),\n",
    "                                                       f1_at_k(y_test_sorted, y_pred_probs_sorted, 30.0),\n",
    "                                                       f1_at_k(y_test_sorted, y_pred_probs_sorted, 40.0),\n",
    "                                                       f1_at_k(y_test_sorted, y_pred_probs_sorted, 50.0)]\n",
    "                                                       \n",
    "                                                      \n",
    "                                                    \n",
    "                    if NOTEBOOK == 1:\n",
    "                        plot_precision_recall_n(y_test,y_pred_probs,clf)\n",
    "                except IndexError as e:\n",
    "                    print('Error:',e)\n",
    "                    continue\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "RF\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-bee508b2757b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mes\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mclf_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_to_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-6dbd0bc27a9d>\u001b[0m in \u001b[0;36mclf_loop\u001b[0;34m(models_to_run, clfs, grid, X, y)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                     \u001b[0my_pred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                     \u001b[0;31m#y_pred = clf.fit(X_train, y_train).predict(X_test)[:,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0;31m# you can also store the model, feature importances, and prediction scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'Timestamp'"
     ]
    }
   ],
   "source": [
    "es= clf_loop(models_to_run, clfs, grid, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "LST = temp_val('2012-01-01','2013-12-31',6,6)\n",
    "\n",
    "\n",
    "def clf_loop(models_to_run, clfs, grid, data, temp_var, label):\n",
    "    \"\"\"Runs the loop using models_to_run, clfs, gridm and the data\n",
    "    \"\"\"\n",
    "    results_df =  pd.DataFrame(columns=('train_end_date','model_type','clf', 'parameters', 'auc-roc','p_at_5', \n",
    "                                        'p_at_10', 'p_at_20','p_at_30', 'p_at_40','p_at_50',\n",
    "                                        'r_at_5','r_at_10','r_at_20','r_at_30','r_at_40','r_at_50',\n",
    "                                        'f1_at_5','f1_at_10','f1_at_20','f1_at_30','f1_at_40','f1_at_50'))\n",
    "    \n",
    "\n",
    "    for elem in LST:\n",
    "        # create training and valdation sets\n",
    "        X_train, X_test, y_train, y_test = temp_spl(data,temp_var,elem,label)\n",
    "\n",
    "        for index,clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "            print(models_to_run[index])\n",
    "            parameter_values = grid[models_to_run[index]]\n",
    "            for p in ParameterGrid(parameter_values):\n",
    "                try:\n",
    "                    clf.set_params(**p)\n",
    "                    y_pred_probs = clf.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "                    #y_pred = clf.fit(X_train, y_train).predict(X_test)[:,1]\n",
    "                    # you can also store the model, feature importances, and prediction scores\n",
    "                    # we're only storing the metrics for now\n",
    "                    #y_pred_probs_sorted, y_pred_sorted, y_test_sorted = zip(*sorted(zip(y_pred_probs, y_pred, y_test), reverse=True))\n",
    "                    y_pred_probs_sorted, y_test_sorted = zip(*sorted(zip(y_pred_probs,y_test), reverse=True))\n",
    "                    #y_pred_sorted, y_test_sorted_ = zip(*sorted(zip(y_pred,y_test), reverse=True))\n",
    "                    results_df.loc[len(results_df)] = [elem[1],models_to_run[index],clf, p,\n",
    "                                                       roc_auc_score(y_test, y_pred_probs),\n",
    "                                                       precision_at_k(y_test_sorted, y_pred_probs_sorted, 5.0),\n",
    "                                                       precision_at_k(y_test_sorted, y_pred_probs_sorted, 10.0),\n",
    "                                                       precision_at_k(y_test_sorted, y_pred_probs_sorted, 20.0),\n",
    "                                                       precision_at_k(y_test_sorted, y_pred_probs_sorted, 30.0),\n",
    "                                                       precision_at_k(y_test_sorted, y_pred_probs_sorted, 40.0),\n",
    "                                                       precision_at_k(y_test_sorted, y_pred_probs_sorted, 50.0),\n",
    "                                                       recall_at_k(y_test_sorted, y_pred_probs_sorted, 5.0),\n",
    "                                                       recall_at_k(y_test_sorted, y_pred_probs_sorted,10.0),\n",
    "                                                       recall_at_k(y_test_sorted, y_pred_probs_sorted, 20.0),\n",
    "                                                       recall_at_k(y_test_sorted, y_pred_probs_sorted, 30.0),\n",
    "                                                       recall_at_k(y_test_sorted, y_pred_probs_sorted, 40.0),\n",
    "                                                       recall_at_k(y_test_sorted, y_pred_probs_sorted, 50.0),\n",
    "                                                       f1_at_k(y_test_sorted, y_pred_probs_sorted, 5.0),\n",
    "                                                       f1_at_k(y_test_sorted, y_pred_probs_sorted,10.0),\n",
    "                                                       f1_at_k(y_test_sorted, y_pred_probs_sorted, 20.0),\n",
    "                                                       f1_at_k(y_test_sorted, y_pred_probs_sorted, 30.0),\n",
    "                                                       f1_at_k(y_test_sorted, y_pred_probs_sorted, 40.0),\n",
    "                                                       f1_at_k(y_test_sorted, y_pred_probs_sorted, 50.0)]\n",
    "                                                       \n",
    "                                                      \n",
    "                                                    \n",
    "                    if NOTEBOOK == 1:\n",
    "                        plot_precision_recall_n(y_test,y_pred_probs,clf)\n",
    "                except IndexError as e:\n",
    "                    print('Error:',e)\n",
    "                    continue\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "DT\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "LR\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "RF\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "DT\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "LR\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "RF\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "DT\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "LR\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n",
      "<class 'numpy.ndarray'> xtrain\n",
      "<class 'numpy.ndarray'> ytrain\n",
      "<class 'numpy.ndarray'> xtest\n",
      "<class 'numpy.ndarray'> ytest\n"
     ]
    }
   ],
   "source": [
    "results_df = clf_loop(models_to_run,clfs,grid,data,'date_posted','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_end_date</th>\n",
       "      <th>model_type</th>\n",
       "      <th>clf</th>\n",
       "      <th>parameters</th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>p_at_40</th>\n",
       "      <th>...</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>r_at_40</th>\n",
       "      <th>r_at_50</th>\n",
       "      <th>f1_at_5</th>\n",
       "      <th>f1_at_10</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>f1_at_30</th>\n",
       "      <th>f1_at_40</th>\n",
       "      <th>f1_at_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'sqrt', 'max_de...</td>\n",
       "      <td>0.660831</td>\n",
       "      <td>0.939062</td>\n",
       "      <td>0.929921</td>\n",
       "      <td>0.902956</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.857404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243089</td>\n",
       "      <td>0.354114</td>\n",
       "      <td>0.461652</td>\n",
       "      <td>0.560290</td>\n",
       "      <td>0.118434</td>\n",
       "      <td>0.220648</td>\n",
       "      <td>0.383054</td>\n",
       "      <td>0.504499</td>\n",
       "      <td>0.600160</td>\n",
       "      <td>0.669772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'sqrt', 'max_de...</td>\n",
       "      <td>0.664888</td>\n",
       "      <td>0.953077</td>\n",
       "      <td>0.936929</td>\n",
       "      <td>0.907831</td>\n",
       "      <td>0.878834</td>\n",
       "      <td>0.858166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244402</td>\n",
       "      <td>0.354893</td>\n",
       "      <td>0.462062</td>\n",
       "      <td>0.562956</td>\n",
       "      <td>0.120201</td>\n",
       "      <td>0.222311</td>\n",
       "      <td>0.385122</td>\n",
       "      <td>0.505609</td>\n",
       "      <td>0.600693</td>\n",
       "      <td>0.672959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'sqrt', 'max_de...</td>\n",
       "      <td>0.660227</td>\n",
       "      <td>0.948812</td>\n",
       "      <td>0.932663</td>\n",
       "      <td>0.905850</td>\n",
       "      <td>0.879240</td>\n",
       "      <td>0.852757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243868</td>\n",
       "      <td>0.355057</td>\n",
       "      <td>0.459150</td>\n",
       "      <td>0.560290</td>\n",
       "      <td>0.119663</td>\n",
       "      <td>0.221298</td>\n",
       "      <td>0.384282</td>\n",
       "      <td>0.505843</td>\n",
       "      <td>0.596907</td>\n",
       "      <td>0.669772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'sqrt', 'max_de...</td>\n",
       "      <td>0.665932</td>\n",
       "      <td>0.959781</td>\n",
       "      <td>0.936624</td>\n",
       "      <td>0.912401</td>\n",
       "      <td>0.880662</td>\n",
       "      <td>0.859842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245632</td>\n",
       "      <td>0.355631</td>\n",
       "      <td>0.462964</td>\n",
       "      <td>0.563736</td>\n",
       "      <td>0.121047</td>\n",
       "      <td>0.222238</td>\n",
       "      <td>0.387061</td>\n",
       "      <td>0.506661</td>\n",
       "      <td>0.601866</td>\n",
       "      <td>0.673890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'log2', 'max_de...</td>\n",
       "      <td>0.662530</td>\n",
       "      <td>0.936624</td>\n",
       "      <td>0.921694</td>\n",
       "      <td>0.903717</td>\n",
       "      <td>0.877006</td>\n",
       "      <td>0.856185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243294</td>\n",
       "      <td>0.354155</td>\n",
       "      <td>0.460996</td>\n",
       "      <td>0.562464</td>\n",
       "      <td>0.118126</td>\n",
       "      <td>0.218696</td>\n",
       "      <td>0.383377</td>\n",
       "      <td>0.504558</td>\n",
       "      <td>0.599307</td>\n",
       "      <td>0.672370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'log2', 'max_de...</td>\n",
       "      <td>0.667507</td>\n",
       "      <td>0.954906</td>\n",
       "      <td>0.941499</td>\n",
       "      <td>0.910878</td>\n",
       "      <td>0.882693</td>\n",
       "      <td>0.862508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245222</td>\n",
       "      <td>0.356451</td>\n",
       "      <td>0.464400</td>\n",
       "      <td>0.564310</td>\n",
       "      <td>0.120432</td>\n",
       "      <td>0.223395</td>\n",
       "      <td>0.386415</td>\n",
       "      <td>0.507830</td>\n",
       "      <td>0.603732</td>\n",
       "      <td>0.674577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'log2', 'max_de...</td>\n",
       "      <td>0.656113</td>\n",
       "      <td>0.943937</td>\n",
       "      <td>0.914381</td>\n",
       "      <td>0.889244</td>\n",
       "      <td>0.871623</td>\n",
       "      <td>0.852377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239398</td>\n",
       "      <td>0.351981</td>\n",
       "      <td>0.458945</td>\n",
       "      <td>0.559265</td>\n",
       "      <td>0.119049</td>\n",
       "      <td>0.216961</td>\n",
       "      <td>0.377238</td>\n",
       "      <td>0.501461</td>\n",
       "      <td>0.596641</td>\n",
       "      <td>0.668546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'log2', 'max_de...</td>\n",
       "      <td>0.664710</td>\n",
       "      <td>0.951859</td>\n",
       "      <td>0.934796</td>\n",
       "      <td>0.908440</td>\n",
       "      <td>0.880967</td>\n",
       "      <td>0.858166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244566</td>\n",
       "      <td>0.355754</td>\n",
       "      <td>0.462062</td>\n",
       "      <td>0.562669</td>\n",
       "      <td>0.120048</td>\n",
       "      <td>0.221805</td>\n",
       "      <td>0.385381</td>\n",
       "      <td>0.506837</td>\n",
       "      <td>0.600693</td>\n",
       "      <td>0.672615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'sqrt', 'max_de...</td>\n",
       "      <td>0.602240</td>\n",
       "      <td>0.669714</td>\n",
       "      <td>0.805302</td>\n",
       "      <td>0.801036</td>\n",
       "      <td>0.833130</td>\n",
       "      <td>0.780469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215651</td>\n",
       "      <td>0.336437</td>\n",
       "      <td>0.420228</td>\n",
       "      <td>0.554589</td>\n",
       "      <td>0.084464</td>\n",
       "      <td>0.191079</td>\n",
       "      <td>0.339818</td>\n",
       "      <td>0.479315</td>\n",
       "      <td>0.546308</td>\n",
       "      <td>0.662957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'sqrt', 'max_de...</td>\n",
       "      <td>0.620788</td>\n",
       "      <td>0.888483</td>\n",
       "      <td>0.878428</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>0.844404</td>\n",
       "      <td>0.824116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232754</td>\n",
       "      <td>0.340989</td>\n",
       "      <td>0.443729</td>\n",
       "      <td>0.546920</td>\n",
       "      <td>0.112055</td>\n",
       "      <td>0.208430</td>\n",
       "      <td>0.366768</td>\n",
       "      <td>0.485801</td>\n",
       "      <td>0.576860</td>\n",
       "      <td>0.653789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'sqrt', 'max_de...</td>\n",
       "      <td>0.632567</td>\n",
       "      <td>0.915905</td>\n",
       "      <td>0.896100</td>\n",
       "      <td>0.867459</td>\n",
       "      <td>0.847959</td>\n",
       "      <td>0.834095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233533</td>\n",
       "      <td>0.342425</td>\n",
       "      <td>0.449102</td>\n",
       "      <td>0.550160</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.212623</td>\n",
       "      <td>0.367996</td>\n",
       "      <td>0.487846</td>\n",
       "      <td>0.583844</td>\n",
       "      <td>0.657662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'sqrt', 'max_de...</td>\n",
       "      <td>0.645078</td>\n",
       "      <td>0.931749</td>\n",
       "      <td>0.913772</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.864006</td>\n",
       "      <td>0.843464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237839</td>\n",
       "      <td>0.348905</td>\n",
       "      <td>0.454147</td>\n",
       "      <td>0.555246</td>\n",
       "      <td>0.117511</td>\n",
       "      <td>0.216816</td>\n",
       "      <td>0.374782</td>\n",
       "      <td>0.497078</td>\n",
       "      <td>0.590403</td>\n",
       "      <td>0.663741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'log2', 'max_de...</td>\n",
       "      <td>0.598811</td>\n",
       "      <td>0.694698</td>\n",
       "      <td>0.787325</td>\n",
       "      <td>0.791590</td>\n",
       "      <td>0.824904</td>\n",
       "      <td>0.775518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213108</td>\n",
       "      <td>0.333115</td>\n",
       "      <td>0.417562</td>\n",
       "      <td>0.552006</td>\n",
       "      <td>0.087615</td>\n",
       "      <td>0.186813</td>\n",
       "      <td>0.335811</td>\n",
       "      <td>0.474582</td>\n",
       "      <td>0.542842</td>\n",
       "      <td>0.659868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'log2', 'max_de...</td>\n",
       "      <td>0.616758</td>\n",
       "      <td>0.882998</td>\n",
       "      <td>0.873553</td>\n",
       "      <td>0.858013</td>\n",
       "      <td>0.841560</td>\n",
       "      <td>0.824802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230990</td>\n",
       "      <td>0.339841</td>\n",
       "      <td>0.444098</td>\n",
       "      <td>0.544418</td>\n",
       "      <td>0.111363</td>\n",
       "      <td>0.207273</td>\n",
       "      <td>0.363989</td>\n",
       "      <td>0.484165</td>\n",
       "      <td>0.577339</td>\n",
       "      <td>0.650798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'log2', 'max_de...</td>\n",
       "      <td>0.626594</td>\n",
       "      <td>0.919561</td>\n",
       "      <td>0.897623</td>\n",
       "      <td>0.869439</td>\n",
       "      <td>0.846740</td>\n",
       "      <td>0.830591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234066</td>\n",
       "      <td>0.341933</td>\n",
       "      <td>0.447215</td>\n",
       "      <td>0.547781</td>\n",
       "      <td>0.115974</td>\n",
       "      <td>0.212984</td>\n",
       "      <td>0.368836</td>\n",
       "      <td>0.487145</td>\n",
       "      <td>0.581392</td>\n",
       "      <td>0.654818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_jobs': -1, 'max_features': 'log2', 'max_de...</td>\n",
       "      <td>0.643817</td>\n",
       "      <td>0.925046</td>\n",
       "      <td>0.910116</td>\n",
       "      <td>0.876143</td>\n",
       "      <td>0.862888</td>\n",
       "      <td>0.843769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235871</td>\n",
       "      <td>0.348454</td>\n",
       "      <td>0.454311</td>\n",
       "      <td>0.556681</td>\n",
       "      <td>0.116666</td>\n",
       "      <td>0.215949</td>\n",
       "      <td>0.371680</td>\n",
       "      <td>0.496436</td>\n",
       "      <td>0.590616</td>\n",
       "      <td>0.665457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878428</td>\n",
       "      <td>0.747105</td>\n",
       "      <td>0.831404</td>\n",
       "      <td>0.873553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201132</td>\n",
       "      <td>0.335739</td>\n",
       "      <td>0.470347</td>\n",
       "      <td>0.604954</td>\n",
       "      <td>0.126119</td>\n",
       "      <td>0.208430</td>\n",
       "      <td>0.316939</td>\n",
       "      <td>0.478322</td>\n",
       "      <td>0.611464</td>\n",
       "      <td>0.723163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878428</td>\n",
       "      <td>0.747105</td>\n",
       "      <td>0.831404</td>\n",
       "      <td>0.873553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201132</td>\n",
       "      <td>0.335739</td>\n",
       "      <td>0.470347</td>\n",
       "      <td>0.604954</td>\n",
       "      <td>0.126119</td>\n",
       "      <td>0.208430</td>\n",
       "      <td>0.316939</td>\n",
       "      <td>0.478322</td>\n",
       "      <td>0.611464</td>\n",
       "      <td>0.723163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878428</td>\n",
       "      <td>0.747105</td>\n",
       "      <td>0.831404</td>\n",
       "      <td>0.873553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201132</td>\n",
       "      <td>0.335739</td>\n",
       "      <td>0.470347</td>\n",
       "      <td>0.604954</td>\n",
       "      <td>0.126119</td>\n",
       "      <td>0.208430</td>\n",
       "      <td>0.316939</td>\n",
       "      <td>0.478322</td>\n",
       "      <td>0.611464</td>\n",
       "      <td>0.723163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.651602</td>\n",
       "      <td>0.931749</td>\n",
       "      <td>0.930225</td>\n",
       "      <td>0.895643</td>\n",
       "      <td>0.860756</td>\n",
       "      <td>0.850091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241120</td>\n",
       "      <td>0.347592</td>\n",
       "      <td>0.457715</td>\n",
       "      <td>0.563530</td>\n",
       "      <td>0.117511</td>\n",
       "      <td>0.220720</td>\n",
       "      <td>0.379952</td>\n",
       "      <td>0.495209</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>0.673645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.651602</td>\n",
       "      <td>0.931749</td>\n",
       "      <td>0.930225</td>\n",
       "      <td>0.895643</td>\n",
       "      <td>0.860756</td>\n",
       "      <td>0.850091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241120</td>\n",
       "      <td>0.347592</td>\n",
       "      <td>0.457715</td>\n",
       "      <td>0.563530</td>\n",
       "      <td>0.117511</td>\n",
       "      <td>0.220720</td>\n",
       "      <td>0.379952</td>\n",
       "      <td>0.495209</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>0.673645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.651881</td>\n",
       "      <td>0.932358</td>\n",
       "      <td>0.930530</td>\n",
       "      <td>0.895795</td>\n",
       "      <td>0.860857</td>\n",
       "      <td>0.850168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241162</td>\n",
       "      <td>0.347634</td>\n",
       "      <td>0.457756</td>\n",
       "      <td>0.563571</td>\n",
       "      <td>0.117588</td>\n",
       "      <td>0.220792</td>\n",
       "      <td>0.380017</td>\n",
       "      <td>0.495267</td>\n",
       "      <td>0.595095</td>\n",
       "      <td>0.673694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.625549</td>\n",
       "      <td>0.800122</td>\n",
       "      <td>0.881475</td>\n",
       "      <td>0.871877</td>\n",
       "      <td>0.849685</td>\n",
       "      <td>0.836533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234722</td>\n",
       "      <td>0.343122</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>0.554220</td>\n",
       "      <td>0.100911</td>\n",
       "      <td>0.209153</td>\n",
       "      <td>0.369870</td>\n",
       "      <td>0.488840</td>\n",
       "      <td>0.585551</td>\n",
       "      <td>0.662516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.626475</td>\n",
       "      <td>0.812310</td>\n",
       "      <td>0.882084</td>\n",
       "      <td>0.867307</td>\n",
       "      <td>0.848771</td>\n",
       "      <td>0.837142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233492</td>\n",
       "      <td>0.342753</td>\n",
       "      <td>0.450742</td>\n",
       "      <td>0.554548</td>\n",
       "      <td>0.102448</td>\n",
       "      <td>0.209297</td>\n",
       "      <td>0.367931</td>\n",
       "      <td>0.488314</td>\n",
       "      <td>0.585977</td>\n",
       "      <td>0.662908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.625432</td>\n",
       "      <td>0.817185</td>\n",
       "      <td>0.881475</td>\n",
       "      <td>0.868678</td>\n",
       "      <td>0.848974</td>\n",
       "      <td>0.836837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233861</td>\n",
       "      <td>0.342835</td>\n",
       "      <td>0.450578</td>\n",
       "      <td>0.554877</td>\n",
       "      <td>0.103063</td>\n",
       "      <td>0.209153</td>\n",
       "      <td>0.368513</td>\n",
       "      <td>0.488431</td>\n",
       "      <td>0.585764</td>\n",
       "      <td>0.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.556607</td>\n",
       "      <td>0.999391</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>0.634979</td>\n",
       "      <td>0.642088</td>\n",
       "      <td>0.731566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170946</td>\n",
       "      <td>0.259290</td>\n",
       "      <td>0.393897</td>\n",
       "      <td>0.528505</td>\n",
       "      <td>0.126042</td>\n",
       "      <td>0.237204</td>\n",
       "      <td>0.269372</td>\n",
       "      <td>0.369405</td>\n",
       "      <td>0.512077</td>\n",
       "      <td>0.631775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.559793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.643358</td>\n",
       "      <td>0.671542</td>\n",
       "      <td>0.753656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173202</td>\n",
       "      <td>0.271184</td>\n",
       "      <td>0.405791</td>\n",
       "      <td>0.527971</td>\n",
       "      <td>0.126119</td>\n",
       "      <td>0.237276</td>\n",
       "      <td>0.272927</td>\n",
       "      <td>0.386350</td>\n",
       "      <td>0.527539</td>\n",
       "      <td>0.631138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.570609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930530</td>\n",
       "      <td>0.620506</td>\n",
       "      <td>0.747004</td>\n",
       "      <td>0.796161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167049</td>\n",
       "      <td>0.301657</td>\n",
       "      <td>0.428677</td>\n",
       "      <td>0.531622</td>\n",
       "      <td>0.126119</td>\n",
       "      <td>0.220792</td>\n",
       "      <td>0.263233</td>\n",
       "      <td>0.429765</td>\n",
       "      <td>0.557291</td>\n",
       "      <td>0.635501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>0.545654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269215</td>\n",
       "      <td>0.403822</td>\n",
       "      <td>0.538430</td>\n",
       "      <td>0.673079</td>\n",
       "      <td>0.126119</td>\n",
       "      <td>0.237276</td>\n",
       "      <td>0.424223</td>\n",
       "      <td>0.575318</td>\n",
       "      <td>0.699973</td>\n",
       "      <td>0.804599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>0.551525</td>\n",
       "      <td>0.999391</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>0.770414</td>\n",
       "      <td>0.846943</td>\n",
       "      <td>0.885207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207407</td>\n",
       "      <td>0.342015</td>\n",
       "      <td>0.476622</td>\n",
       "      <td>0.611230</td>\n",
       "      <td>0.126042</td>\n",
       "      <td>0.237204</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>0.487262</td>\n",
       "      <td>0.619621</td>\n",
       "      <td>0.730665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>0.555878</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.746963</td>\n",
       "      <td>0.831303</td>\n",
       "      <td>0.873482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208677</td>\n",
       "      <td>0.348345</td>\n",
       "      <td>0.488044</td>\n",
       "      <td>0.627680</td>\n",
       "      <td>0.130491</td>\n",
       "      <td>0.245047</td>\n",
       "      <td>0.326219</td>\n",
       "      <td>0.490960</td>\n",
       "      <td>0.626205</td>\n",
       "      <td>0.739142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>0.569796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.624475</td>\n",
       "      <td>0.637403</td>\n",
       "      <td>0.728062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174458</td>\n",
       "      <td>0.267094</td>\n",
       "      <td>0.406793</td>\n",
       "      <td>0.534695</td>\n",
       "      <td>0.130551</td>\n",
       "      <td>0.245102</td>\n",
       "      <td>0.272725</td>\n",
       "      <td>0.376444</td>\n",
       "      <td>0.521953</td>\n",
       "      <td>0.629645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>0.600365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685967</td>\n",
       "      <td>0.842888</td>\n",
       "      <td>0.895255</td>\n",
       "      <td>0.921444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235475</td>\n",
       "      <td>0.375143</td>\n",
       "      <td>0.514842</td>\n",
       "      <td>0.654510</td>\n",
       "      <td>0.130551</td>\n",
       "      <td>0.168132</td>\n",
       "      <td>0.368112</td>\n",
       "      <td>0.528729</td>\n",
       "      <td>0.660590</td>\n",
       "      <td>0.770736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>0.600365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685967</td>\n",
       "      <td>0.842888</td>\n",
       "      <td>0.895255</td>\n",
       "      <td>0.921444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235475</td>\n",
       "      <td>0.375143</td>\n",
       "      <td>0.514842</td>\n",
       "      <td>0.654510</td>\n",
       "      <td>0.130551</td>\n",
       "      <td>0.168132</td>\n",
       "      <td>0.368112</td>\n",
       "      <td>0.528729</td>\n",
       "      <td>0.660590</td>\n",
       "      <td>0.770736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>0.600365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685967</td>\n",
       "      <td>0.842888</td>\n",
       "      <td>0.895255</td>\n",
       "      <td>0.921444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235475</td>\n",
       "      <td>0.375143</td>\n",
       "      <td>0.514842</td>\n",
       "      <td>0.654510</td>\n",
       "      <td>0.130551</td>\n",
       "      <td>0.168132</td>\n",
       "      <td>0.368112</td>\n",
       "      <td>0.528729</td>\n",
       "      <td>0.660590</td>\n",
       "      <td>0.770736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.664884</td>\n",
       "      <td>0.939600</td>\n",
       "      <td>0.928701</td>\n",
       "      <td>0.903508</td>\n",
       "      <td>0.850072</td>\n",
       "      <td>0.823022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252410</td>\n",
       "      <td>0.356210</td>\n",
       "      <td>0.459850</td>\n",
       "      <td>0.573988</td>\n",
       "      <td>0.122666</td>\n",
       "      <td>0.227627</td>\n",
       "      <td>0.394586</td>\n",
       "      <td>0.502045</td>\n",
       "      <td>0.590031</td>\n",
       "      <td>0.675916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.664884</td>\n",
       "      <td>0.939600</td>\n",
       "      <td>0.928701</td>\n",
       "      <td>0.903508</td>\n",
       "      <td>0.850072</td>\n",
       "      <td>0.823022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252410</td>\n",
       "      <td>0.356210</td>\n",
       "      <td>0.459850</td>\n",
       "      <td>0.573988</td>\n",
       "      <td>0.122666</td>\n",
       "      <td>0.227627</td>\n",
       "      <td>0.394586</td>\n",
       "      <td>0.502045</td>\n",
       "      <td>0.590031</td>\n",
       "      <td>0.675916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.664884</td>\n",
       "      <td>0.939600</td>\n",
       "      <td>0.928701</td>\n",
       "      <td>0.903508</td>\n",
       "      <td>0.850072</td>\n",
       "      <td>0.823022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252410</td>\n",
       "      <td>0.356210</td>\n",
       "      <td>0.459850</td>\n",
       "      <td>0.573988</td>\n",
       "      <td>0.122666</td>\n",
       "      <td>0.227627</td>\n",
       "      <td>0.394586</td>\n",
       "      <td>0.502045</td>\n",
       "      <td>0.590031</td>\n",
       "      <td>0.675916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.662936</td>\n",
       "      <td>0.878747</td>\n",
       "      <td>0.903724</td>\n",
       "      <td>0.886480</td>\n",
       "      <td>0.857035</td>\n",
       "      <td>0.839312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247653</td>\n",
       "      <td>0.359127</td>\n",
       "      <td>0.468952</td>\n",
       "      <td>0.570088</td>\n",
       "      <td>0.114721</td>\n",
       "      <td>0.221505</td>\n",
       "      <td>0.387150</td>\n",
       "      <td>0.506157</td>\n",
       "      <td>0.601709</td>\n",
       "      <td>0.671322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.662895</td>\n",
       "      <td>0.878292</td>\n",
       "      <td>0.903270</td>\n",
       "      <td>0.886480</td>\n",
       "      <td>0.857035</td>\n",
       "      <td>0.839255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247653</td>\n",
       "      <td>0.359127</td>\n",
       "      <td>0.468920</td>\n",
       "      <td>0.570119</td>\n",
       "      <td>0.114662</td>\n",
       "      <td>0.221394</td>\n",
       "      <td>0.387150</td>\n",
       "      <td>0.506157</td>\n",
       "      <td>0.601668</td>\n",
       "      <td>0.671360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.662996</td>\n",
       "      <td>0.878747</td>\n",
       "      <td>0.905540</td>\n",
       "      <td>0.887388</td>\n",
       "      <td>0.857489</td>\n",
       "      <td>0.839255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247907</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>0.468920</td>\n",
       "      <td>0.570278</td>\n",
       "      <td>0.114721</td>\n",
       "      <td>0.221950</td>\n",
       "      <td>0.387546</td>\n",
       "      <td>0.506425</td>\n",
       "      <td>0.601668</td>\n",
       "      <td>0.671546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min...</td>\n",
       "      <td>0.588232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888283</td>\n",
       "      <td>0.613918</td>\n",
       "      <td>0.742602</td>\n",
       "      <td>0.788001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171508</td>\n",
       "      <td>0.311176</td>\n",
       "      <td>0.440283</td>\n",
       "      <td>0.547190</td>\n",
       "      <td>0.130551</td>\n",
       "      <td>0.217720</td>\n",
       "      <td>0.268114</td>\n",
       "      <td>0.438574</td>\n",
       "      <td>0.564924</td>\n",
       "      <td>0.644359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min...</td>\n",
       "      <td>0.591938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838329</td>\n",
       "      <td>0.641844</td>\n",
       "      <td>0.761220</td>\n",
       "      <td>0.792996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179310</td>\n",
       "      <td>0.318978</td>\n",
       "      <td>0.443074</td>\n",
       "      <td>0.547634</td>\n",
       "      <td>0.130551</td>\n",
       "      <td>0.205476</td>\n",
       "      <td>0.280310</td>\n",
       "      <td>0.449570</td>\n",
       "      <td>0.568505</td>\n",
       "      <td>0.644882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min...</td>\n",
       "      <td>0.595964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745686</td>\n",
       "      <td>0.693722</td>\n",
       "      <td>0.795353</td>\n",
       "      <td>0.798615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193803</td>\n",
       "      <td>0.333280</td>\n",
       "      <td>0.446213</td>\n",
       "      <td>0.546492</td>\n",
       "      <td>0.130551</td>\n",
       "      <td>0.182769</td>\n",
       "      <td>0.302967</td>\n",
       "      <td>0.469728</td>\n",
       "      <td>0.572533</td>\n",
       "      <td>0.643537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>0.544428</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279367</td>\n",
       "      <td>0.419035</td>\n",
       "      <td>0.558734</td>\n",
       "      <td>0.698402</td>\n",
       "      <td>0.130551</td>\n",
       "      <td>0.245102</td>\n",
       "      <td>0.436727</td>\n",
       "      <td>0.590591</td>\n",
       "      <td>0.716907</td>\n",
       "      <td>0.822422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>0.551683</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.795664</td>\n",
       "      <td>0.863771</td>\n",
       "      <td>0.897832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222282</td>\n",
       "      <td>0.361950</td>\n",
       "      <td>0.501649</td>\n",
       "      <td>0.641285</td>\n",
       "      <td>0.130491</td>\n",
       "      <td>0.245047</td>\n",
       "      <td>0.347488</td>\n",
       "      <td>0.510135</td>\n",
       "      <td>0.643662</td>\n",
       "      <td>0.755163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>0.562645</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.625043</td>\n",
       "      <td>0.610838</td>\n",
       "      <td>0.708139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174616</td>\n",
       "      <td>0.255962</td>\n",
       "      <td>0.395662</td>\n",
       "      <td>0.535297</td>\n",
       "      <td>0.130491</td>\n",
       "      <td>0.245047</td>\n",
       "      <td>0.272973</td>\n",
       "      <td>0.360755</td>\n",
       "      <td>0.507670</td>\n",
       "      <td>0.630354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>0.544367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279367</td>\n",
       "      <td>0.419035</td>\n",
       "      <td>0.558734</td>\n",
       "      <td>0.698402</td>\n",
       "      <td>0.130551</td>\n",
       "      <td>0.245102</td>\n",
       "      <td>0.436727</td>\n",
       "      <td>0.590591</td>\n",
       "      <td>0.716907</td>\n",
       "      <td>0.822422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>0.552715</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.809399</td>\n",
       "      <td>0.872928</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226119</td>\n",
       "      <td>0.365787</td>\n",
       "      <td>0.505486</td>\n",
       "      <td>0.645122</td>\n",
       "      <td>0.130491</td>\n",
       "      <td>0.245047</td>\n",
       "      <td>0.353487</td>\n",
       "      <td>0.515544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>0.759682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>0.562502</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.625043</td>\n",
       "      <td>0.602513</td>\n",
       "      <td>0.701896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174616</td>\n",
       "      <td>0.252474</td>\n",
       "      <td>0.392173</td>\n",
       "      <td>0.531809</td>\n",
       "      <td>0.130491</td>\n",
       "      <td>0.245047</td>\n",
       "      <td>0.272973</td>\n",
       "      <td>0.355839</td>\n",
       "      <td>0.503194</td>\n",
       "      <td>0.626246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'l1'}</td>\n",
       "      <td>0.384590</td>\n",
       "      <td>0.604450</td>\n",
       "      <td>0.622616</td>\n",
       "      <td>0.640595</td>\n",
       "      <td>0.640960</td>\n",
       "      <td>0.639062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178961</td>\n",
       "      <td>0.268584</td>\n",
       "      <td>0.357066</td>\n",
       "      <td>0.451066</td>\n",
       "      <td>0.078911</td>\n",
       "      <td>0.152605</td>\n",
       "      <td>0.279765</td>\n",
       "      <td>0.378545</td>\n",
       "      <td>0.458149</td>\n",
       "      <td>0.531165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'l2'}</td>\n",
       "      <td>0.437005</td>\n",
       "      <td>0.655767</td>\n",
       "      <td>0.655995</td>\n",
       "      <td>0.662731</td>\n",
       "      <td>0.671536</td>\n",
       "      <td>0.673062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185145</td>\n",
       "      <td>0.281397</td>\n",
       "      <td>0.376062</td>\n",
       "      <td>0.472441</td>\n",
       "      <td>0.085611</td>\n",
       "      <td>0.160786</td>\n",
       "      <td>0.289433</td>\n",
       "      <td>0.396603</td>\n",
       "      <td>0.482523</td>\n",
       "      <td>0.556336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>0.638309</td>\n",
       "      <td>0.914623</td>\n",
       "      <td>0.882607</td>\n",
       "      <td>0.838234</td>\n",
       "      <td>0.820480</td>\n",
       "      <td>0.812862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234175</td>\n",
       "      <td>0.343809</td>\n",
       "      <td>0.454174</td>\n",
       "      <td>0.559527</td>\n",
       "      <td>0.119405</td>\n",
       "      <td>0.216329</td>\n",
       "      <td>0.366079</td>\n",
       "      <td>0.484568</td>\n",
       "      <td>0.582747</td>\n",
       "      <td>0.658886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.644650</td>\n",
       "      <td>0.894641</td>\n",
       "      <td>0.875114</td>\n",
       "      <td>0.846975</td>\n",
       "      <td>0.835238</td>\n",
       "      <td>0.822057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236617</td>\n",
       "      <td>0.349994</td>\n",
       "      <td>0.459311</td>\n",
       "      <td>0.561017</td>\n",
       "      <td>0.116796</td>\n",
       "      <td>0.214492</td>\n",
       "      <td>0.369897</td>\n",
       "      <td>0.493284</td>\n",
       "      <td>0.589339</td>\n",
       "      <td>0.660642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.650808</td>\n",
       "      <td>0.899183</td>\n",
       "      <td>0.880790</td>\n",
       "      <td>0.853105</td>\n",
       "      <td>0.838114</td>\n",
       "      <td>0.824271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238329</td>\n",
       "      <td>0.351199</td>\n",
       "      <td>0.460548</td>\n",
       "      <td>0.564823</td>\n",
       "      <td>0.117389</td>\n",
       "      <td>0.215884</td>\n",
       "      <td>0.372574</td>\n",
       "      <td>0.494983</td>\n",
       "      <td>0.590926</td>\n",
       "      <td>0.665123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.649557</td>\n",
       "      <td>0.899183</td>\n",
       "      <td>0.879655</td>\n",
       "      <td>0.852083</td>\n",
       "      <td>0.837281</td>\n",
       "      <td>0.823476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238044</td>\n",
       "      <td>0.350850</td>\n",
       "      <td>0.460104</td>\n",
       "      <td>0.563935</td>\n",
       "      <td>0.117389</td>\n",
       "      <td>0.215606</td>\n",
       "      <td>0.372128</td>\n",
       "      <td>0.494491</td>\n",
       "      <td>0.590356</td>\n",
       "      <td>0.664077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>0.651147</td>\n",
       "      <td>0.901453</td>\n",
       "      <td>0.879882</td>\n",
       "      <td>0.853672</td>\n",
       "      <td>0.838492</td>\n",
       "      <td>0.824384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238488</td>\n",
       "      <td>0.351357</td>\n",
       "      <td>0.460611</td>\n",
       "      <td>0.564950</td>\n",
       "      <td>0.117685</td>\n",
       "      <td>0.215661</td>\n",
       "      <td>0.372822</td>\n",
       "      <td>0.495206</td>\n",
       "      <td>0.591007</td>\n",
       "      <td>0.665272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.649655</td>\n",
       "      <td>0.897366</td>\n",
       "      <td>0.877611</td>\n",
       "      <td>0.851856</td>\n",
       "      <td>0.837357</td>\n",
       "      <td>0.823135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237980</td>\n",
       "      <td>0.350882</td>\n",
       "      <td>0.459914</td>\n",
       "      <td>0.564220</td>\n",
       "      <td>0.117152</td>\n",
       "      <td>0.215105</td>\n",
       "      <td>0.372028</td>\n",
       "      <td>0.494536</td>\n",
       "      <td>0.590112</td>\n",
       "      <td>0.664413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.651156</td>\n",
       "      <td>0.900999</td>\n",
       "      <td>0.880109</td>\n",
       "      <td>0.853559</td>\n",
       "      <td>0.838492</td>\n",
       "      <td>0.824327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238456</td>\n",
       "      <td>0.351357</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.564982</td>\n",
       "      <td>0.117626</td>\n",
       "      <td>0.215717</td>\n",
       "      <td>0.372772</td>\n",
       "      <td>0.495206</td>\n",
       "      <td>0.590966</td>\n",
       "      <td>0.665310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.649874</td>\n",
       "      <td>0.896912</td>\n",
       "      <td>0.877838</td>\n",
       "      <td>0.852083</td>\n",
       "      <td>0.837811</td>\n",
       "      <td>0.823306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238044</td>\n",
       "      <td>0.351072</td>\n",
       "      <td>0.460009</td>\n",
       "      <td>0.564252</td>\n",
       "      <td>0.117093</td>\n",
       "      <td>0.215160</td>\n",
       "      <td>0.372128</td>\n",
       "      <td>0.494804</td>\n",
       "      <td>0.590234</td>\n",
       "      <td>0.664451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_end_date model_type  \\\n",
       "0       2012-07-01         RF   \n",
       "1       2012-07-01         RF   \n",
       "2       2012-07-01         RF   \n",
       "3       2012-07-01         RF   \n",
       "4       2012-07-01         RF   \n",
       "5       2012-07-01         RF   \n",
       "6       2012-07-01         RF   \n",
       "7       2012-07-01         RF   \n",
       "8       2012-07-01         RF   \n",
       "9       2012-07-01         RF   \n",
       "10      2012-07-01         RF   \n",
       "11      2012-07-01         RF   \n",
       "12      2012-07-01         RF   \n",
       "13      2012-07-01         RF   \n",
       "14      2012-07-01         RF   \n",
       "15      2012-07-01         RF   \n",
       "16      2012-07-01         DT   \n",
       "17      2012-07-01         DT   \n",
       "18      2012-07-01         DT   \n",
       "19      2012-07-01         DT   \n",
       "20      2012-07-01         DT   \n",
       "21      2012-07-01         DT   \n",
       "22      2012-07-01         DT   \n",
       "23      2012-07-01         DT   \n",
       "24      2012-07-01         DT   \n",
       "25      2012-07-01         DT   \n",
       "26      2012-07-01         DT   \n",
       "27      2012-07-01         DT   \n",
       "28      2012-07-01         DT   \n",
       "29      2012-07-01         DT   \n",
       "..             ...        ...   \n",
       "156     2013-07-01         DT   \n",
       "157     2013-07-01         DT   \n",
       "158     2013-07-01         DT   \n",
       "159     2013-07-01         DT   \n",
       "160     2013-07-01         DT   \n",
       "161     2013-07-01         DT   \n",
       "162     2013-07-01         DT   \n",
       "163     2013-07-01         DT   \n",
       "164     2013-07-01         DT   \n",
       "165     2013-07-01         DT   \n",
       "166     2013-07-01         DT   \n",
       "167     2013-07-01         DT   \n",
       "168     2013-07-01         DT   \n",
       "169     2013-07-01         DT   \n",
       "170     2013-07-01         DT   \n",
       "171     2013-07-01         DT   \n",
       "172     2013-07-01         DT   \n",
       "173     2013-07-01         DT   \n",
       "174     2013-07-01         DT   \n",
       "175     2013-07-01         DT   \n",
       "176     2013-07-01         LR   \n",
       "177     2013-07-01         LR   \n",
       "178     2013-07-01         LR   \n",
       "179     2013-07-01         LR   \n",
       "180     2013-07-01         LR   \n",
       "181     2013-07-01         LR   \n",
       "182     2013-07-01         LR   \n",
       "183     2013-07-01         LR   \n",
       "184     2013-07-01         LR   \n",
       "185     2013-07-01         LR   \n",
       "\n",
       "                                                   clf  \\\n",
       "0    (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "1    (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "2    (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "3    (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "4    (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "5    (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "6    (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "7    (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "8    (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "9    (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "10   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "11   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "12   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "13   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "14   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "15   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "16   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "17   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "18   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "19   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "20   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "21   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "22   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "23   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "24   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "25   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "26   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "27   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "28   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "29   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "..                                                 ...   \n",
       "156  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "157  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "158  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "159  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "160  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "161  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "162  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "163  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "164  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "165  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "166  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "167  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "168  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "169  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "170  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "171  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "172  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "173  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "174  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "175  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "176  LogisticRegression(C=10, class_weight=None, du...   \n",
       "177  LogisticRegression(C=10, class_weight=None, du...   \n",
       "178  LogisticRegression(C=10, class_weight=None, du...   \n",
       "179  LogisticRegression(C=10, class_weight=None, du...   \n",
       "180  LogisticRegression(C=10, class_weight=None, du...   \n",
       "181  LogisticRegression(C=10, class_weight=None, du...   \n",
       "182  LogisticRegression(C=10, class_weight=None, du...   \n",
       "183  LogisticRegression(C=10, class_weight=None, du...   \n",
       "184  LogisticRegression(C=10, class_weight=None, du...   \n",
       "185  LogisticRegression(C=10, class_weight=None, du...   \n",
       "\n",
       "                                            parameters   auc-roc    p_at_5  \\\n",
       "0    {'n_jobs': -1, 'max_features': 'sqrt', 'max_de...  0.660831  0.939062   \n",
       "1    {'n_jobs': -1, 'max_features': 'sqrt', 'max_de...  0.664888  0.953077   \n",
       "2    {'n_jobs': -1, 'max_features': 'sqrt', 'max_de...  0.660227  0.948812   \n",
       "3    {'n_jobs': -1, 'max_features': 'sqrt', 'max_de...  0.665932  0.959781   \n",
       "4    {'n_jobs': -1, 'max_features': 'log2', 'max_de...  0.662530  0.936624   \n",
       "5    {'n_jobs': -1, 'max_features': 'log2', 'max_de...  0.667507  0.954906   \n",
       "6    {'n_jobs': -1, 'max_features': 'log2', 'max_de...  0.656113  0.943937   \n",
       "7    {'n_jobs': -1, 'max_features': 'log2', 'max_de...  0.664710  0.951859   \n",
       "8    {'n_jobs': -1, 'max_features': 'sqrt', 'max_de...  0.602240  0.669714   \n",
       "9    {'n_jobs': -1, 'max_features': 'sqrt', 'max_de...  0.620788  0.888483   \n",
       "10   {'n_jobs': -1, 'max_features': 'sqrt', 'max_de...  0.632567  0.915905   \n",
       "11   {'n_jobs': -1, 'max_features': 'sqrt', 'max_de...  0.645078  0.931749   \n",
       "12   {'n_jobs': -1, 'max_features': 'log2', 'max_de...  0.598811  0.694698   \n",
       "13   {'n_jobs': -1, 'max_features': 'log2', 'max_de...  0.616758  0.882998   \n",
       "14   {'n_jobs': -1, 'max_features': 'log2', 'max_de...  0.626594  0.919561   \n",
       "15   {'n_jobs': -1, 'max_features': 'log2', 'max_de...  0.643817  0.925046   \n",
       "16   {'criterion': 'gini', 'max_depth': 1, 'min_sam...  0.603960  1.000000   \n",
       "17   {'criterion': 'gini', 'max_depth': 1, 'min_sam...  0.603960  1.000000   \n",
       "18   {'criterion': 'gini', 'max_depth': 1, 'min_sam...  0.603960  1.000000   \n",
       "19   {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.651602  0.931749   \n",
       "20   {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.651602  0.931749   \n",
       "21   {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.651881  0.932358   \n",
       "22   {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.625549  0.800122   \n",
       "23   {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.626475  0.812310   \n",
       "24   {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.625432  0.817185   \n",
       "25   {'criterion': 'gini', 'max_depth': 20, 'min_sa...  0.556607  0.999391   \n",
       "26   {'criterion': 'gini', 'max_depth': 20, 'min_sa...  0.559793  1.000000   \n",
       "27   {'criterion': 'gini', 'max_depth': 20, 'min_sa...  0.570609  1.000000   \n",
       "28   {'criterion': 'gini', 'max_depth': 50, 'min_sa...  0.545654  1.000000   \n",
       "29   {'criterion': 'gini', 'max_depth': 50, 'min_sa...  0.551525  0.999391   \n",
       "..                                                 ...       ...       ...   \n",
       "156  {'criterion': 'gini', 'max_depth': 100, 'min_s...  0.555878  0.999546   \n",
       "157  {'criterion': 'gini', 'max_depth': 100, 'min_s...  0.569796  1.000000   \n",
       "158  {'criterion': 'entropy', 'max_depth': 1, 'min_...  0.600365  1.000000   \n",
       "159  {'criterion': 'entropy', 'max_depth': 1, 'min_...  0.600365  1.000000   \n",
       "160  {'criterion': 'entropy', 'max_depth': 1, 'min_...  0.600365  1.000000   \n",
       "161  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.664884  0.939600   \n",
       "162  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.664884  0.939600   \n",
       "163  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.664884  0.939600   \n",
       "164  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.662936  0.878747   \n",
       "165  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.662895  0.878292   \n",
       "166  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.662996  0.878747   \n",
       "167  {'criterion': 'entropy', 'max_depth': 20, 'min...  0.588232  1.000000   \n",
       "168  {'criterion': 'entropy', 'max_depth': 20, 'min...  0.591938  1.000000   \n",
       "169  {'criterion': 'entropy', 'max_depth': 20, 'min...  0.595964  1.000000   \n",
       "170  {'criterion': 'entropy', 'max_depth': 50, 'min...  0.544428  1.000000   \n",
       "171  {'criterion': 'entropy', 'max_depth': 50, 'min...  0.551683  0.999546   \n",
       "172  {'criterion': 'entropy', 'max_depth': 50, 'min...  0.562645  0.999546   \n",
       "173  {'criterion': 'entropy', 'max_depth': 100, 'mi...  0.544367  1.000000   \n",
       "174  {'criterion': 'entropy', 'max_depth': 100, 'mi...  0.552715  0.999546   \n",
       "175  {'criterion': 'entropy', 'max_depth': 100, 'mi...  0.562502  0.999546   \n",
       "176                      {'C': 1e-05, 'penalty': 'l1'}  0.384590  0.604450   \n",
       "177                      {'C': 1e-05, 'penalty': 'l2'}  0.437005  0.655767   \n",
       "178                      {'C': 0.001, 'penalty': 'l1'}  0.638309  0.914623   \n",
       "179                      {'C': 0.001, 'penalty': 'l2'}  0.644650  0.894641   \n",
       "180                        {'C': 0.1, 'penalty': 'l1'}  0.650808  0.899183   \n",
       "181                        {'C': 0.1, 'penalty': 'l2'}  0.649557  0.899183   \n",
       "182                          {'C': 1, 'penalty': 'l1'}  0.651147  0.901453   \n",
       "183                          {'C': 1, 'penalty': 'l2'}  0.649655  0.897366   \n",
       "184                         {'C': 10, 'penalty': 'l1'}  0.651156  0.900999   \n",
       "185                         {'C': 10, 'penalty': 'l2'}  0.649874  0.896912   \n",
       "\n",
       "      p_at_10   p_at_20   p_at_30   p_at_40    ...      r_at_20   r_at_30  \\\n",
       "0    0.929921  0.902956  0.876904  0.857404    ...     0.243089  0.354114   \n",
       "1    0.936929  0.907831  0.878834  0.858166    ...     0.244402  0.354893   \n",
       "2    0.932663  0.905850  0.879240  0.852757    ...     0.243868  0.355057   \n",
       "3    0.936624  0.912401  0.880662  0.859842    ...     0.245632  0.355631   \n",
       "4    0.921694  0.903717  0.877006  0.856185    ...     0.243294  0.354155   \n",
       "5    0.941499  0.910878  0.882693  0.862508    ...     0.245222  0.356451   \n",
       "6    0.914381  0.889244  0.871623  0.852377    ...     0.239398  0.351981   \n",
       "7    0.934796  0.908440  0.880967  0.858166    ...     0.244566  0.355754   \n",
       "8    0.805302  0.801036  0.833130  0.780469    ...     0.215651  0.336437   \n",
       "9    0.878428  0.864564  0.844404  0.824116    ...     0.232754  0.340989   \n",
       "10   0.896100  0.867459  0.847959  0.834095    ...     0.233533  0.342425   \n",
       "11   0.913772  0.883455  0.864006  0.843464    ...     0.237839  0.348905   \n",
       "12   0.787325  0.791590  0.824904  0.775518    ...     0.213108  0.333115   \n",
       "13   0.873553  0.858013  0.841560  0.824802    ...     0.230990  0.339841   \n",
       "14   0.897623  0.869439  0.846740  0.830591    ...     0.234066  0.341933   \n",
       "15   0.910116  0.876143  0.862888  0.843769    ...     0.235871  0.348454   \n",
       "16   0.878428  0.747105  0.831404  0.873553    ...     0.201132  0.335739   \n",
       "17   0.878428  0.747105  0.831404  0.873553    ...     0.201132  0.335739   \n",
       "18   0.878428  0.747105  0.831404  0.873553    ...     0.201132  0.335739   \n",
       "19   0.930225  0.895643  0.860756  0.850091    ...     0.241120  0.347592   \n",
       "20   0.930225  0.895643  0.860756  0.850091    ...     0.241120  0.347592   \n",
       "21   0.930530  0.895795  0.860857  0.850168    ...     0.241162  0.347634   \n",
       "22   0.881475  0.871877  0.849685  0.836533    ...     0.234722  0.343122   \n",
       "23   0.882084  0.867307  0.848771  0.837142    ...     0.233492  0.342753   \n",
       "24   0.881475  0.868678  0.848974  0.836837    ...     0.233861  0.342835   \n",
       "25   0.999695  0.634979  0.642088  0.731566    ...     0.170946  0.259290   \n",
       "26   1.000000  0.643358  0.671542  0.753656    ...     0.173202  0.271184   \n",
       "27   0.930530  0.620506  0.747004  0.796161    ...     0.167049  0.301657   \n",
       "28   1.000000  1.000000  1.000000  1.000000    ...     0.269215  0.403822   \n",
       "29   0.999695  0.770414  0.846943  0.885207    ...     0.207407  0.342015   \n",
       "..        ...       ...       ...       ...    ...          ...       ...   \n",
       "156  0.999773  0.746963  0.831303  0.873482    ...     0.208677  0.348345   \n",
       "157  1.000000  0.624475  0.637403  0.728062    ...     0.174458  0.267094   \n",
       "158  0.685967  0.842888  0.895255  0.921444    ...     0.235475  0.375143   \n",
       "159  0.685967  0.842888  0.895255  0.921444    ...     0.235475  0.375143   \n",
       "160  0.685967  0.842888  0.895255  0.921444    ...     0.235475  0.375143   \n",
       "161  0.928701  0.903508  0.850072  0.823022    ...     0.252410  0.356210   \n",
       "162  0.928701  0.903508  0.850072  0.823022    ...     0.252410  0.356210   \n",
       "163  0.928701  0.903508  0.850072  0.823022    ...     0.252410  0.356210   \n",
       "164  0.903724  0.886480  0.857035  0.839312    ...     0.247653  0.359127   \n",
       "165  0.903270  0.886480  0.857035  0.839255    ...     0.247653  0.359127   \n",
       "166  0.905540  0.887388  0.857489  0.839255    ...     0.247907  0.359318   \n",
       "167  0.888283  0.613918  0.742602  0.788001    ...     0.171508  0.311176   \n",
       "168  0.838329  0.641844  0.761220  0.792996    ...     0.179310  0.318978   \n",
       "169  0.745686  0.693722  0.795353  0.798615    ...     0.193803  0.333280   \n",
       "170  1.000000  1.000000  1.000000  1.000000    ...     0.279367  0.419035   \n",
       "171  0.999773  0.795664  0.863771  0.897832    ...     0.222282  0.361950   \n",
       "172  0.999773  0.625043  0.610838  0.708139    ...     0.174616  0.255962   \n",
       "173  1.000000  1.000000  1.000000  1.000000    ...     0.279367  0.419035   \n",
       "174  0.999773  0.809399  0.872928  0.904700    ...     0.226119  0.365787   \n",
       "175  0.999773  0.625043  0.602513  0.701896    ...     0.174616  0.252474   \n",
       "176  0.622616  0.640595  0.640960  0.639062    ...     0.178961  0.268584   \n",
       "177  0.655995  0.662731  0.671536  0.673062    ...     0.185145  0.281397   \n",
       "178  0.882607  0.838234  0.820480  0.812862    ...     0.234175  0.343809   \n",
       "179  0.875114  0.846975  0.835238  0.822057    ...     0.236617  0.349994   \n",
       "180  0.880790  0.853105  0.838114  0.824271    ...     0.238329  0.351199   \n",
       "181  0.879655  0.852083  0.837281  0.823476    ...     0.238044  0.350850   \n",
       "182  0.879882  0.853672  0.838492  0.824384    ...     0.238488  0.351357   \n",
       "183  0.877611  0.851856  0.837357  0.823135    ...     0.237980  0.350882   \n",
       "184  0.880109  0.853559  0.838492  0.824327    ...     0.238456  0.351357   \n",
       "185  0.877838  0.852083  0.837811  0.823306    ...     0.238044  0.351072   \n",
       "\n",
       "      r_at_40   r_at_50   f1_at_5  f1_at_10  f1_at_20  f1_at_30  f1_at_40  \\\n",
       "0    0.461652  0.560290  0.118434  0.220648  0.383054  0.504499  0.600160   \n",
       "1    0.462062  0.562956  0.120201  0.222311  0.385122  0.505609  0.600693   \n",
       "2    0.459150  0.560290  0.119663  0.221298  0.384282  0.505843  0.596907   \n",
       "3    0.462964  0.563736  0.121047  0.222238  0.387061  0.506661  0.601866   \n",
       "4    0.460996  0.562464  0.118126  0.218696  0.383377  0.504558  0.599307   \n",
       "5    0.464400  0.564310  0.120432  0.223395  0.386415  0.507830  0.603732   \n",
       "6    0.458945  0.559265  0.119049  0.216961  0.377238  0.501461  0.596641   \n",
       "7    0.462062  0.562669  0.120048  0.221805  0.385381  0.506837  0.600693   \n",
       "8    0.420228  0.554589  0.084464  0.191079  0.339818  0.479315  0.546308   \n",
       "9    0.443729  0.546920  0.112055  0.208430  0.366768  0.485801  0.576860   \n",
       "10   0.449102  0.550160  0.115513  0.212623  0.367996  0.487846  0.583844   \n",
       "11   0.454147  0.555246  0.117511  0.216816  0.374782  0.497078  0.590403   \n",
       "12   0.417562  0.552006  0.087615  0.186813  0.335811  0.474582  0.542842   \n",
       "13   0.444098  0.544418  0.111363  0.207273  0.363989  0.484165  0.577339   \n",
       "14   0.447215  0.547781  0.115974  0.212984  0.368836  0.487145  0.581392   \n",
       "15   0.454311  0.556681  0.116666  0.215949  0.371680  0.496436  0.590616   \n",
       "16   0.470347  0.604954  0.126119  0.208430  0.316939  0.478322  0.611464   \n",
       "17   0.470347  0.604954  0.126119  0.208430  0.316939  0.478322  0.611464   \n",
       "18   0.470347  0.604954  0.126119  0.208430  0.316939  0.478322  0.611464   \n",
       "19   0.457715  0.563530  0.117511  0.220720  0.379952  0.495209  0.595041   \n",
       "20   0.457715  0.563530  0.117511  0.220720  0.379952  0.495209  0.595041   \n",
       "21   0.457756  0.563571  0.117588  0.220792  0.380017  0.495267  0.595095   \n",
       "22   0.450414  0.554220  0.100911  0.209153  0.369870  0.488840  0.585551   \n",
       "23   0.450742  0.554548  0.102448  0.209297  0.367931  0.488314  0.585977   \n",
       "24   0.450578  0.554877  0.103063  0.209153  0.368513  0.488431  0.585764   \n",
       "25   0.393897  0.528505  0.126042  0.237204  0.269372  0.369405  0.512077   \n",
       "26   0.405791  0.527971  0.126119  0.237276  0.272927  0.386350  0.527539   \n",
       "27   0.428677  0.531622  0.126119  0.220792  0.263233  0.429765  0.557291   \n",
       "28   0.538430  0.673079  0.126119  0.237276  0.424223  0.575318  0.699973   \n",
       "29   0.476622  0.611230  0.126042  0.237204  0.326827  0.487262  0.619621   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "156  0.488044  0.627680  0.130491  0.245047  0.326219  0.490960  0.626205   \n",
       "157  0.406793  0.534695  0.130551  0.245102  0.272725  0.376444  0.521953   \n",
       "158  0.514842  0.654510  0.130551  0.168132  0.368112  0.528729  0.660590   \n",
       "159  0.514842  0.654510  0.130551  0.168132  0.368112  0.528729  0.660590   \n",
       "160  0.514842  0.654510  0.130551  0.168132  0.368112  0.528729  0.660590   \n",
       "161  0.459850  0.573988  0.122666  0.227627  0.394586  0.502045  0.590031   \n",
       "162  0.459850  0.573988  0.122666  0.227627  0.394586  0.502045  0.590031   \n",
       "163  0.459850  0.573988  0.122666  0.227627  0.394586  0.502045  0.590031   \n",
       "164  0.468952  0.570088  0.114721  0.221505  0.387150  0.506157  0.601709   \n",
       "165  0.468920  0.570119  0.114662  0.221394  0.387150  0.506157  0.601668   \n",
       "166  0.468920  0.570278  0.114721  0.221950  0.387546  0.506425  0.601668   \n",
       "167  0.440283  0.547190  0.130551  0.217720  0.268114  0.438574  0.564924   \n",
       "168  0.443074  0.547634  0.130551  0.205476  0.280310  0.449570  0.568505   \n",
       "169  0.446213  0.546492  0.130551  0.182769  0.302967  0.469728  0.572533   \n",
       "170  0.558734  0.698402  0.130551  0.245102  0.436727  0.590591  0.716907   \n",
       "171  0.501649  0.641285  0.130491  0.245047  0.347488  0.510135  0.643662   \n",
       "172  0.395662  0.535297  0.130491  0.245047  0.272973  0.360755  0.507670   \n",
       "173  0.558734  0.698402  0.130551  0.245102  0.436727  0.590591  0.716907   \n",
       "174  0.505486  0.645122  0.130491  0.245047  0.353487  0.515544  0.648586   \n",
       "175  0.392173  0.531809  0.130491  0.245047  0.272973  0.355839  0.503194   \n",
       "176  0.357066  0.451066  0.078911  0.152605  0.279765  0.378545  0.458149   \n",
       "177  0.376062  0.472441  0.085611  0.160786  0.289433  0.396603  0.482523   \n",
       "178  0.454174  0.559527  0.119405  0.216329  0.366079  0.484568  0.582747   \n",
       "179  0.459311  0.561017  0.116796  0.214492  0.369897  0.493284  0.589339   \n",
       "180  0.460548  0.564823  0.117389  0.215884  0.372574  0.494983  0.590926   \n",
       "181  0.460104  0.563935  0.117389  0.215606  0.372128  0.494491  0.590356   \n",
       "182  0.460611  0.564950  0.117685  0.215661  0.372822  0.495206  0.591007   \n",
       "183  0.459914  0.564220  0.117152  0.215105  0.372028  0.494536  0.590112   \n",
       "184  0.460580  0.564982  0.117626  0.215717  0.372772  0.495206  0.590966   \n",
       "185  0.460009  0.564252  0.117093  0.215160  0.372128  0.494804  0.590234   \n",
       "\n",
       "     f1_at_50  \n",
       "0    0.669772  \n",
       "1    0.672959  \n",
       "2    0.669772  \n",
       "3    0.673890  \n",
       "4    0.672370  \n",
       "5    0.674577  \n",
       "6    0.668546  \n",
       "7    0.672615  \n",
       "8    0.662957  \n",
       "9    0.653789  \n",
       "10   0.657662  \n",
       "11   0.663741  \n",
       "12   0.659868  \n",
       "13   0.650798  \n",
       "14   0.654818  \n",
       "15   0.665457  \n",
       "16   0.723163  \n",
       "17   0.723163  \n",
       "18   0.723163  \n",
       "19   0.673645  \n",
       "20   0.673645  \n",
       "21   0.673694  \n",
       "22   0.662516  \n",
       "23   0.662908  \n",
       "24   0.663300  \n",
       "25   0.631775  \n",
       "26   0.631138  \n",
       "27   0.635501  \n",
       "28   0.804599  \n",
       "29   0.730665  \n",
       "..        ...  \n",
       "156  0.739142  \n",
       "157  0.629645  \n",
       "158  0.770736  \n",
       "159  0.770736  \n",
       "160  0.770736  \n",
       "161  0.675916  \n",
       "162  0.675916  \n",
       "163  0.675916  \n",
       "164  0.671322  \n",
       "165  0.671360  \n",
       "166  0.671546  \n",
       "167  0.644359  \n",
       "168  0.644882  \n",
       "169  0.643537  \n",
       "170  0.822422  \n",
       "171  0.755163  \n",
       "172  0.630354  \n",
       "173  0.822422  \n",
       "174  0.759682  \n",
       "175  0.626246  \n",
       "176  0.531165  \n",
       "177  0.556336  \n",
       "178  0.658886  \n",
       "179  0.660642  \n",
       "180  0.665123  \n",
       "181  0.664077  \n",
       "182  0.665272  \n",
       "183  0.664413  \n",
       "184  0.665310  \n",
       "185  0.664451  \n",
       "\n",
       "[186 rows x 23 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': -1}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['parameters'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-fc5cd309065a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
